{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEpW7bBoXxjK",
    "outputId": "f9291846-3e60-4b81-a287-2488653ef2c8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ejN3IJoBX01S",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import hinge_loss, mean_absolute_error,mean_squared_log_error,median_absolute_error,mean_absolute_percentage_error,mean_poisson_deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6xhdLfrpYEE2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411\n"
     ]
    }
   ],
   "source": [
    "file_path = '../dataset.json'\n",
    "\n",
    "# Open the file and load its contents\n",
    "with open(file_path, 'r') as json_file:\n",
    "    # Read the file content\n",
    "    file_content = json_file.read()\n",
    "\n",
    "    # Split the content by newline to get individual JSON objects\n",
    "    json_objects = file_content.split('\\n')\n",
    "\n",
    "data = []\n",
    "# Process each JSON object\n",
    "for json_object in json_objects:\n",
    "    if json_object.strip() == '':\n",
    "        continue  # Skip empty lines\n",
    "    \n",
    "    # Parse the JSON object\n",
    "    data.append(json.loads(json_object))\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "Y_flat = []\n",
    "\n",
    "for i in data:\n",
    "    X.append(np.array(i['vector']))    \n",
    "    Y.append(np.array(i['matrix']))\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.4, random_state=44)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train_flat =[i.flatten() for i in Y_train]\n",
    "Y_test_flat =[i.flatten() for i in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_metrics(y, p_y):\n",
    "    metrics = {}\n",
    "    try:\n",
    "        metrics['mse'] = mse(y,p_y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        metrics['hinge_loss'] = hinge_losss(y,p_y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        metrics['mean_absolute_error'] = mean_absolute_error(y,p_y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        metrics['mean_squared_log_error'] = mean_squared_log_error(y,p_y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        metrics['median_absolute_error'] = median_absolute_error(y,p_y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        metrics['mean_absolute_percentage_error'] = mean_absolute_percentage_error(y,p_y)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        metrics['mean_poisson_deviance'] = mean_poisson_deviance(y,p_y)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handmade NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rliz9aQlYEXS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "def build_crazy_model(input_dim, output_dim):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dense(2048, activation='relu'),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dense(output_dim)\n",
    "    ])\n",
    "    return model\n",
    "def build_model(input_dim, output_dim):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(196)  # Output layer with shape (196,)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_model_recursive(input_dim, output_dim):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Reshape((1, 256)),  # Reshape input to match LSTM requirements\n",
    "        # tf.keras.layers.LSTM(512, return_sequences=True),\n",
    "        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='relu')),\n",
    "        tf.keras.layers.LSTM(512),\n",
    "        tf.keras.layers.Dense(output_dim)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# def build_model_convolutional(input_dim):\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n",
    "#         tf.keras.layers.Dense(7*7*128, activation='relu'),\n",
    "#         tf.keras.layers.Reshape((7, 7, 128)),\n",
    "#         tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu'),\n",
    "#         tf.keras.layers.Conv2DTranspose(2, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu'),\n",
    "#         tf.keras.layers.Conv2D(1, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu'),\n",
    "#         tf.keras.layers.Reshape((14, 14, 1))  # Update the output shape to (14, 14, 1)\n",
    "#     ])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GxPsGwMvYLOD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the input and output dimensions\n",
    "input_dim = 128  # Dimensionality of the input vector\n",
    "output_dim = 196  # Dimensionality of the output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g9uXSFPQYMzE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = build_model_recursive(input_dim, output_dim)\n",
    "model_ann = build_model(input_dim, output_dim)\n",
    "# model_conv = build_model_convolutional(input_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model_ann.compile(optimizer='adam', loss='mse')\n",
    "# model_conv.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyzgGBgHYOp3",
    "outputId": "458e8b0e-378c-4bff-dbe8-741ef2881b4b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27/27 [==============================] - 2s 27ms/step - loss: 1789813.0000\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1535.7041\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1525.1367\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1757.0555\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1603.8358\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1294\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1520.1285\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1520.1277\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1268\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1256\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1251\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1232\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 1520.1224\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1212\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1199\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 1520.1189\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1174\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1160\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1147\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1133\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1116\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1102\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1083\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1072\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1056\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1039\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1021\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.1005\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.0988\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 1520.0972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa91ad7e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ann.fit(x=np.array(X_train),y=np.array(Y_train_flat), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMOPGW57eW2x",
    "outputId": "c0e955d5-1de1-423d-d28d-2a9a57a1a3ab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "27/27 [==============================] - 3s 14ms/step - loss: 1519.7838\n",
      "Epoch 2/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1519.5587\n",
      "Epoch 3/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1519.4749\n",
      "Epoch 4/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1519.3931\n",
      "Epoch 5/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1519.2053\n",
      "Epoch 6/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1519.1143\n",
      "Epoch 7/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.9363\n",
      "Epoch 8/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.8491\n",
      "Epoch 9/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.7942\n",
      "Epoch 10/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1519.1202\n",
      "Epoch 11/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1519.0084\n",
      "Epoch 12/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.9216\n",
      "Epoch 13/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.7842\n",
      "Epoch 14/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.6804\n",
      "Epoch 15/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.6044\n",
      "Epoch 16/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.5135\n",
      "Epoch 17/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.3696\n",
      "Epoch 18/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.2231\n",
      "Epoch 19/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1518.0514\n",
      "Epoch 20/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.9264\n",
      "Epoch 21/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.7863\n",
      "Epoch 22/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.6030\n",
      "Epoch 23/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.4662\n",
      "Epoch 24/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.3708\n",
      "Epoch 25/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.2998\n",
      "Epoch 26/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.1960\n",
      "Epoch 27/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.1055\n",
      "Epoch 28/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1517.0319\n",
      "Epoch 29/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1516.9501\n",
      "Epoch 30/30\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 1516.8783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa91aeb710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=np.array(X_train),y=np.array(Y_train_flat), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14SAvXOHYk4y",
    "outputId": "a65e3d8a-9fbb-45d3-c448-2ffbc1d79605",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "{'accuracy': 0.0, 'mse': 74.35198830079388, 'mean_absolute_error': 0.13910764401594042, 'median_absolute_error': 0.09361839123572552, 'mean_absolute_percentage_error': 2.546053918175268}\n",
      "{'accuracy': 0.0, 'mse': 74.68787309301749, 'mean_absolute_error': 0.06742639544786548, 'median_absolute_error': 0.006336912573711696, 'mean_absolute_percentage_error': 15.515945562618311}\n"
     ]
    }
   ],
   "source": [
    "Y_predicted = model.predict(np.array(X_test))\n",
    "Y_ann_predicted = model_ann.predict(np.array(X_test))\n",
    "# Y_conv_predicted = model_conv.predict(np.array(X_test))\n",
    "print(get_metrics(Y_predicted, Y_test_flat))\n",
    "print(get_metrics(Y_ann_predicted, Y_test_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dn__H5iFZ0gY",
    "outputId": "04738f0c-14b0-4c03-e2ed-2e48633b08ae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_predicted = [np.reshape(i, (14,14)) for i in Y_predicted]\n",
    "# Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMhuJWX0ckq3",
    "outputId": "4ce0320e-f93b-481c-811b-7bf4c95fcc7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_ann_predicted = [np.reshape(i, (14,14)) for i in Y_ann_predicted]\n",
    "# Y_ann_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(-1, 128)\n",
    "# Y_train = Y_train.reshape(-1, 14,14)\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, Y_train_flat))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, Y_test_flat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 Complete [00h 00m 04s]\n",
      "val_loss: 217.4120635986328\n",
      "\n",
      "Best val_loss So Far: 211.0436553955078\n",
      "Total elapsed time: 00h 03m 42s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/15\n",
      "27/27 [==============================] - 2s 3ms/step - loss: 1520.5531 - mse: 1520.5531\n",
      "Epoch 2/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1518.2599 - mse: 1518.2599\n",
      "Epoch 3/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1516.9558 - mse: 1516.9558\n",
      "Epoch 4/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1515.7854 - mse: 1515.7854\n",
      "Epoch 5/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1514.7783 - mse: 1514.7783\n",
      "Epoch 6/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1515.7646 - mse: 1515.7646\n",
      "Epoch 7/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1513.7859 - mse: 1513.7859\n",
      "Epoch 8/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1513.4513 - mse: 1513.4513\n",
      "Epoch 9/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1512.0162 - mse: 1512.0162\n",
      "Epoch 10/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1510.7546 - mse: 1510.7546\n",
      "Epoch 11/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1510.1173 - mse: 1510.1173\n",
      "Epoch 12/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1512.2163 - mse: 1512.2163\n",
      "Epoch 13/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1510.1709 - mse: 1510.1709\n",
      "Epoch 14/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1508.8552 - mse: 1508.8552\n",
      "Epoch 15/15\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1507.2659 - mse: 1507.2659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff9f44f1250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_node = ak.StructuredDataInput()\n",
    "output_node = ak.StructuredDataBlock(categorical_encoding=False)(input_node)\n",
    "output_node = ak.RegressionHead()(output_node)\n",
    "reg = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100,metrics=['mse'],\n",
    ")\n",
    "reg.fit(train_set,epochs=15)\n",
    "\n",
    "# X_train = X_train.reshape(-1, 128)\n",
    "# Y_train = Y_train.reshape(-1, 14,14)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 75.0349 - mse: 75.0349\n",
      "[75.03491973876953, 75.03491973876953]\n",
      "{'accuracy': 0.0, 'mse': 75.0349249143321, 'mean_absolute_error': 0.3475291074501781, 'median_absolute_error': 0.23809958837245734, 'mean_absolute_percentage_error': 98378864702.74512}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.11254194e-01, -3.07110369e-01,  1.87819861e-02, ...,\n",
       "        -1.57700226e-01,  1.01653171e+00,  5.53711548e+01],\n",
       "       [-6.74944669e-02, -1.85701981e-01, -1.81589454e-01, ...,\n",
       "        -3.26376669e-02, -4.98163439e-02,  1.04031515e+01],\n",
       "       [-5.30624837e-02, -1.38605028e-01, -3.12669687e-02, ...,\n",
       "        -1.66468009e-01,  4.20905769e-01,  1.15251598e+01],\n",
       "       ...,\n",
       "       [-1.15610018e-01, -2.00630933e-01, -7.42398500e-02, ...,\n",
       "        -3.31348889e-02,  5.41591085e-02,  1.55125389e+01],\n",
       "       [-1.79375961e-01, -3.74882281e-01,  6.52066171e-02, ...,\n",
       "        -2.01920746e-04,  1.02803004e+00,  5.80619202e+01],\n",
       "       [-1.86146632e-01, -2.59324849e-01, -3.22393812e-02, ...,\n",
       "        -4.06718664e-02,  9.36430514e-01,  5.31868515e+01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = reg.predict(test_set)\n",
    "print(reg.evaluate(test_set))\n",
    "print(get_metrics(Y_test_flat, predicted_y))\n",
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 82 Complete [00h 00m 09s]\n",
      "val_loss: 213.0825958251953\n",
      "\n",
      "Best val_loss So Far: 212.44825744628906\n",
      "Total elapsed time: 00h 11m 37s\n",
      "\n",
      "Search: Running Trial #83\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "True              |True              |structured_data_block_1/normalize\n",
      "False             |False             |structured_data_block_1/dense_block_1/use_batchnorm\n",
      "2                 |2                 |structured_data_block_1/dense_block_1/num_layers\n",
      "32                |32                |structured_data_block_1/dense_block_1/units_0\n",
      "0.5               |0                 |structured_data_block_1/dense_block_1/dropout\n",
      "256               |256               |structured_data_block_1/dense_block_1/units_1\n",
      "0                 |0                 |regression_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "16                |16                |structured_data_block_1/dense_block_1/units_2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressor = ak.StructuredDataRegressor(max_trials=100, overwrite=True, metrics=['mse'],)\n",
    "regressor.fit(train_set, epochs=11)\n",
    "predicted_y = regressor.predict(test_set)\n",
    "# X_train = X_train.reshape(-1, 128)\n",
    "# Y_train = Y_train.reshape(-1, 14,14)\n",
    "print(regressor.evaluate(test_set))\n",
    "print(get_metrics(Y_test_flat, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regressor = regressor.export_model()\n",
    "model_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 128)\n",
    "Y_ak_predicted =reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(-1, 128)\n",
    "# Y_train = Y_train.reshape(-1, 14,14)\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node = ak.StructuredDataInput()\n",
    "output_node = ak.StructuredDataBlock(categorical_encoding=True)(input_node)\n",
    "output_node = ak.RegressionHead()(output_node)\n",
    "reg = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=100,metrics=['mse'],\n",
    ")\n",
    "reg.fit(train_set,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = reg.predict(test_set)\n",
    "print(reg.evaluate(test_set))\n",
    "print(get_metrics(Y_test_flat, predicted_y))\n",
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
